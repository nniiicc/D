##Thick & Clean; Thin & Dirty 

While the two approaches described above – thick and dirty, clean and thin- are well established modes of inquiry for social science research, it is a bit harder to imagine or even see the value in research projects that would populate the opposite cells of this matrix - descriptively thin and empirically dirty, or descriptively thick and empirically clean.

Some descriptively thick and empirically clean research can be characterized as a "kitchen sink" approach where every possible statistical test is thrown at a dataset to see what might emerge from the results (Boettke, 2005). 

I argue that this form of research can be more charitably described by data collection that is empirically clean, in that is the result of rigorous computational, and (presumably) reproducible empirical methods used to answer very specific and narrow research questions. As a result of the breadth of resources that are analyzed, and the relative newness of the analytic techniques being used, the results are open to multiple interpretations. Consequently, these empirically clean methods produce a discussion that is wide ranging, and unstructured in its presentation; or in my categorization, thick. 

With increased access to data and open-source “plug and play” software tools, the descriptively thick and empirically clean research approach is becoming more common; Topic modeling projects in the digital humanities(Rosen-Zvi, Chemudugunta, Griffiths, Smyth, and Steyvers, 2010), social network analysis and data mining in computational social science (Keegan, Ahmed, Williams, Srivastava, & Contractor, 2010), and the visualization of sentiment analysis in studies of social media use (Hochman & Schwartz, 2012) are all salient examples of research that is descriptively thick and empirically clean. 

In the opposite cell, descriptively thin and empirically dirty research seems to be the worst of both worlds – these projects would ask broad research questions about diverse subjects and use research methods such as participant interviews or ethnographic observation which are impossible to reproduce. These types of research projects would then generate highly structured descriptions by using the conventions of a previously developed framework – producing thin descriptions of a phenomenon by abstracting from the messiness of an empirically dirty method. 
 
For instance, the Institutional Analysis and Development (IAD) framework  achieves this by asking broad research questions, like "What motivates fishermen to cooperate with one another in sustaining a fishery" (Hutchings & Myers, 1994) and using field-based research methods such as participant observation, interviews, and surveys to gather behavioral data about individual stakeholders. Researchers using the IAD are then guided by a well-established framework that categorizes and organizes the analysis into some thirty different variable groupings (Ostrom, 2005). 

While there may seem to be a high investment for a small payoff for the descriptively thin and empirically dirty approach this mode of inquiry also presents a way to overcome the n = 1 shallowness of a case study. Results fitting into such a structured form of analysis makes it possible for the n= 1 formula to actually become an n = X + 1 where X represents an archive of comparable studies. 
